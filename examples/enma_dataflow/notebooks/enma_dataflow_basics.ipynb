{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this codelab, we will learn how to create some `task` and make a basic `Dataflow` with them by using EnMa-SDK. Next we will learn how to visualize the flow and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first example we will use the following EnMa-SDK dependencies. In this case we import:\n",
    "\n",
    "- **Dataflow:** this is the context manager to define custom `Dataflow`. It has a parameter to give a name to it.\n",
    "- **task:** it is the decorator used for defining the flow tasks. Every function specified with `@task()` can be used inside the `Dataflow`. In this codelab we will use the `name` parameter for give an alias to the task.\n",
    "- **metrics** we can use `metrics` to get some custom metrics during the flow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enma import Dataflow, metrics, task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we use `randmon` and `time` dependencies as part of our example. We have to import it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the resources are imported, we can start defining the tasks for our Dataflow. The tasks for the example are very simple and they are just for showing how to use them.\n",
    "\n",
    "As you can see we set the optional `name` parameter in the first two task, with a different value than the name. When we execute the Dataflow we will see how this name is shown.\n",
    "\n",
    "Inside some task we use the `metrics` module to define some metrics for the Dataflow.\n",
    "\n",
    "We can create as many `task` functions as require our Dataflow.\n",
    "\n",
    "One important thing we have to know about tasks functions is they can return a value or not, but in case they return a value **it's not allowed to return multiple values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(name=\"my-load-data\")\n",
    "def load_data(input_cond):\n",
    "    # Create example data list.\n",
    "    result = input_cond * [1]\n",
    "    \n",
    "    # Define a metric for the data lenth.\n",
    "    metrics.add(\"data_len\", len(result))\n",
    "    return result\n",
    "\n",
    "@task(name=\"custom-transform-data\")\n",
    "def transform_data(data):\n",
    "    # We do some transformation in data.\n",
    "    result2 = [x if random.random() > 0.5 else 0 for x in data]\n",
    "    \n",
    "    # We simulate some delay during the process.\n",
    "    time.sleep(5)\n",
    "    \n",
    "    return result2\n",
    "\n",
    "@task()\n",
    "def get_results(data):\n",
    "    # This task just create another metric.\n",
    "    metrics.add(\"sum_of_data\", sum(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataflow Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the `task` we can define the Dataflow. This is a context manager so we use the statement `with`, give a name to the Dataflow as a parameter and an alias for use it later.\n",
    "\n",
    "Inside the `with` statement we define the flow like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Dataflow(\"my-example-dataflow\") as flow:\n",
    "    # First task is load the data.\n",
    "    out_1 = load_data(10)\n",
    "    \n",
    "    # The second task is doing a simple transformation.\n",
    "    out_2 = transform_data(out_1)\n",
    "    \n",
    "    # The last part is getting the results.\n",
    "    get_results(out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition doesn't mean execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we realize that, despite having introduced a delay as part of the process, the cell has executed instantly.\n",
    "\n",
    "This is because EnMa-SDK handles the definition process inside the context manager and skip the execution of the `task` decorated functions used inside.\n",
    "\n",
    "Internally EnMa-SDK builds the execution graph and let it prepared untill we run the `Dataflow`.\n",
    "\n",
    "One useful functionality which offers EnMa-SDK is `pprint` the `Dataflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graphical representation of the `Dataflow` we can see the execution order of the `task`. This can help us when we define more complicated flows.\n",
    "\n",
    "Each box represents a `node`. This is the internal name of the execution unit, has an **order number** associated, and in the first line of the box we can see the **type** which is `Task` in all of three of the example. Later we will see that there are other differente types.\n",
    "\n",
    "The second line of each box is the **name** of the `node`, or `task` in this case. The first two takes the `name` parameter we set during the `task` definition. Because it is an optional parameter, the third `task` uses the **function name** as value for the **name**.\n",
    "\n",
    "The third line shows the status of the `node`. As we said before, the tasks are not executed yet until we run the `Dataflow`, so `non executed` are the status for the three tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataflow Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can `run` the `Dataflow` from here using the function with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some while depending on the value we put on the sleep call, we get some output information as result of the `run`.\n",
    "\n",
    "First we have the `Dataflow` **representation**. Is the same graph that we saw when `pprint` the flow but now we can see how all tasks have `executed` in the status row. In fact, if we will execute `flow.pprint()` again we will get this same result. This is because now the `Dataflow` has been executed and the information is stored internally.\n",
    "\n",
    "After the flow representation we have a summary about the **performance** of each task. Two important points here, the first one is that only `task` nodes will be measured, and the second is related to `elapsed` values. The measured elapsed time for `task` execution only takes account the real computation time. Because of this, the second task measured time is small than the sleep time.\n",
    "\n",
    "The last part of the outputs is related to the **metrics**. Each row of the table shows the node order number, the name of the node, the metric name and the value for the metric. Using the first two columns we can check in the graph representation where in the flow the metric was created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! We made our first `Dataflow` using EnMa-SDK, understood all the concepts and different parts, ran it and check the output results. Now we are ready for learn more advance features of EnMa-SDK."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
