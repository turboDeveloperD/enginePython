{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataflow notebook\n",
    "\n",
    "Our Dataflow **must** be coded in this notebook. The platform provides some cool automations to ensure the correct dataflow life cycle; this is why we are asking you to please use this notebook. Donâ€™t panic! You can find some useful guidelines in the sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataflow development\n",
    "\n",
    "First, we import the EnMa-SDK and required other packages for Dataflow development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enma import Dataflow, assertion, condition, ifelse, logs, metrics, parameters, task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we develop the dataflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(name=\"a\")\n",
    "def task_a(input_cond):\n",
    "    result = input_cond * [1]\n",
    "    return result\n",
    "\n",
    "\n",
    "@condition()\n",
    "def task_b(stat_choice):\n",
    "    return stat_choice == 0\n",
    "\n",
    "\n",
    "@task(name=\"c\")\n",
    "def task_c(data):\n",
    "    # Define Logs and Metrics\n",
    "    logs.add(\"log_task_c\")\n",
    "    metrics.add(\"metric_task_c\", 3)\n",
    "    return 3\n",
    "\n",
    "\n",
    "@task(name=\"d\")\n",
    "def task_d(data):\n",
    "    # Define Logs and Metrics\n",
    "    logs.add(\"log_task_d\")\n",
    "    metrics.add(\"metric_task_d\", 3)\n",
    "    return 4\n",
    "\n",
    "\n",
    "@assertion(name=\"a_equal_b\")\n",
    "def assert_equals(a, b):\n",
    "    assert a == b\n",
    "\n",
    "\n",
    "with Dataflow(\"my-dummy-etl\") as flow:\n",
    "\n",
    "    # Define Parameters as key,value pairs.   \n",
    "    n_elem = parameters.add(\"n_elem\", 10)\n",
    "    choice = parameters.add(\"choice\", 0)\n",
    "\n",
    "    #Define task within the dataflow.\n",
    "    out_1 = task_a(n_elem)\n",
    "        \n",
    "    # Metrics can be defined at dataflow level (as here) or \n",
    "    # at task level (like in task_c or task_d).\n",
    "    metrics.add(\"metric_flow\", out_1)\n",
    "\n",
    "    # Ifelse condition evaluates the condition defined as task_b. \n",
    "    # If function exection is True executes `task_c` else executes `task_d`.\n",
    "    out_2 = ifelse(\n",
    "        condition=task_b(choice),\n",
    "        true_condition=task_c(out_1),\n",
    "        false_condition=task_d(out_1),\n",
    "    )\n",
    "\n",
    "    # Logs can be defined at dataflow level (as here) or \n",
    "    # at task level (like in task_c or task_d).\n",
    "    logs.add(\"log_flow\")\n",
    "\n",
    "    # Assertion enables to define function which evaluates objects.\n",
    "    assert_equals(out_2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataflow development - Completed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataflow local execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell shows dataflow pipeline diagram with all the information related to each node.\n",
    "\n",
    "Once our dataflow is developed we can run it. The result of the Run shows the pipeline structure again, the elapsed time for each node and a table with the metrics generated at each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.run() # run could accept verbose argument [flow.run(verbose=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register dataflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can register our Dataflow. With the following function a form is shown to push our Dataflow to Bitbucket and register it at the Engine section of Sandbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Register dataflow - Completed**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
